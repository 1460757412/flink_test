2023-04-04 09:23:17  [ main:0 ] - [ INFO ]  Found configuration file file:/Users/renzhuo/IdeaProjects/Flink_test/target/classes/hive-site.xml
2023-04-04 09:23:18  [ main:259 ] - [ INFO ]  Setting hive conf dir as /Users/renzhuo/IdeaProjects/Flink_test/src/main/resources
2023-04-04 09:23:18  [ main:495 ] - [ INFO ]  Created HiveCatalog 'batch_test'
2023-04-04 09:23:18  [ main:509 ] - [ INFO ]  Trying to connect to metastore with URI thrift://t-d-datastorage-srv03:9083
2023-04-04 09:23:18  [ main:592 ] - [ INFO ]  Opened a connection to metastore, current connections: 1
2023-04-04 09:23:18  [ main:632 ] - [ INFO ]  Connected to metastore.
2023-04-04 09:23:18  [ main:681 ] - [ INFO ]  Connected to Hive metastore
2023-04-04 09:24:54  [ main:0 ] - [ INFO ]  Found configuration file file:/Users/renzhuo/IdeaProjects/Flink_test/target/classes/hive-site.xml
2023-04-04 09:24:55  [ main:274 ] - [ INFO ]  Setting hive conf dir as /Users/renzhuo/IdeaProjects/Flink_test/src/main/resources
2023-04-04 09:24:55  [ main:490 ] - [ INFO ]  Created HiveCatalog 'batch_test'
2023-04-04 09:24:55  [ main:504 ] - [ INFO ]  Trying to connect to metastore with URI thrift://t-d-datastorage-srv02:9083
2023-04-04 09:24:55  [ main:796 ] - [ INFO ]  Opened a connection to metastore, current connections: 1
2023-04-04 09:24:55  [ main:926 ] - [ INFO ]  Connected to metastore.
2023-04-04 09:24:55  [ main:987 ] - [ INFO ]  Connected to Hive metastore
2023-04-04 09:38:23  [ main:0 ] - [ INFO ]  Found configuration file file:/Users/renzhuo/IdeaProjects/Flink_test/target/classes/hive-site.xml
2023-04-04 09:38:24  [ main:298 ] - [ INFO ]  Setting hive conf dir as /Users/renzhuo/IdeaProjects/Flink_test/src/main/resources
2023-04-04 09:38:24  [ main:545 ] - [ INFO ]  Created HiveCatalog 'batch_test'
2023-04-04 09:38:24  [ main:560 ] - [ INFO ]  Trying to connect to metastore with URI thrift://t-d-datastorage-srv03:9083
2023-04-04 09:38:24  [ main:774 ] - [ INFO ]  Opened a connection to metastore, current connections: 1
2023-04-04 09:38:24  [ main:852 ] - [ INFO ]  Connected to metastore.
2023-04-04 09:38:24  [ main:912 ] - [ INFO ]  Connected to Hive metastore
2023-04-04 09:38:27  [ main:3531 ] - [ WARN ]  HiveConf of name hive.vectorized.use.checked.expressions does not exist
2023-04-04 09:38:27  [ main:3532 ] - [ WARN ]  HiveConf of name hive.strict.checks.no.partition.filter does not exist
2023-04-04 09:38:27  [ main:3532 ] - [ WARN ]  HiveConf of name hive.strict.checks.orderby.no.limit does not exist
2023-04-04 09:38:27  [ main:3532 ] - [ WARN ]  HiveConf of name hive.vectorized.adaptor.usage.mode does not exist
2023-04-04 09:38:27  [ main:3532 ] - [ WARN ]  HiveConf of name hive.vectorized.input.format.excludes does not exist
2023-04-04 09:38:27  [ main:3532 ] - [ WARN ]  HiveConf of name hive.strict.checks.bucketing does not exist
2023-04-04 09:38:27  [ main:3537 ] - [ INFO ]  Trying to connect to metastore with URI thrift://t-d-datastorage-srv04:9083
2023-04-04 09:38:27  [ main:3804 ] - [ INFO ]  Opened a connection to metastore, current connections: 2
2023-04-04 09:38:27  [ main:4002 ] - [ INFO ]  Connected to metastore.
2023-04-04 09:38:28  [ main:4237 ] - [ INFO ]  Closed a connection to metastore, current connections: 1
2023-04-04 09:38:28  [ main:4946 ] - [ WARN ]  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2023-04-04 09:38:29  [ main:5325 ] - [ INFO ]  Hive source(dwd.employee_dimission}) getNumFiles use time: 1087 ms, result: 1
2023-04-04 09:38:29  [ main:5525 ] - [ INFO ]  Total input files to process : 1
2023-04-04 09:38:29  [ main:5534 ] - [ INFO ]  Hive source(dwd.employee_dimission}) createInputSplits use time: 209 ms, result: 1
2023-04-04 09:38:29  [ main:5875 ] - [ INFO ]  The configuration option taskmanager.cpu.cores required for local execution is not set, setting it to the maximal possible value.
2023-04-04 09:38:29  [ main:5875 ] - [ INFO ]  The configuration option taskmanager.memory.task.heap.size required for local execution is not set, setting it to the maximal possible value.
2023-04-04 09:38:29  [ main:5876 ] - [ INFO ]  The configuration option taskmanager.memory.task.off-heap.size required for local execution is not set, setting it to the maximal possible value.
2023-04-04 09:38:29  [ main:5876 ] - [ INFO ]  The configuration option taskmanager.memory.network.min required for local execution is not set, setting it to its default value 64 mb.
2023-04-04 09:38:29  [ main:5876 ] - [ INFO ]  The configuration option taskmanager.memory.network.max required for local execution is not set, setting it to its default value 64 mb.
2023-04-04 09:38:29  [ main:5876 ] - [ INFO ]  The configuration option taskmanager.memory.managed.size required for local execution is not set, setting it to its default value 128 mb.
2023-04-04 09:38:29  [ main:5880 ] - [ INFO ]  Starting Flink Mini Cluster
2023-04-04 09:38:30  [ main:6100 ] - [ INFO ]  Starting Metrics Registry
2023-04-04 09:38:30  [ main:6131 ] - [ INFO ]  No metrics reporter configured, no metrics will be exposed/reported.
2023-04-04 09:38:30  [ main:6132 ] - [ INFO ]  Starting RPC Service(s)
2023-04-04 09:38:30  [ main:6141 ] - [ INFO ]  Trying to start local actor system
2023-04-04 09:38:30  [ flink-akka.actor.default-dispatcher-5:6586 ] - [ INFO ]  Slf4jLogger started
2023-04-04 09:38:30  [ main:6675 ] - [ INFO ]  Actor system started at akka://flink
2023-04-04 09:38:30  [ main:6688 ] - [ INFO ]  Trying to start local actor system
2023-04-04 09:38:30  [ flink-metrics-5:6698 ] - [ INFO ]  Slf4jLogger started
2023-04-04 09:38:30  [ main:6704 ] - [ INFO ]  Actor system started at akka://flink-metrics
2023-04-04 09:38:30  [ main:6713 ] - [ INFO ]  Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService .
2023-04-04 09:38:30  [ main:6762 ] - [ INFO ]  Starting high-availability services
2023-04-04 09:38:30  [ main:6770 ] - [ INFO ]  Created BLOB server storage directory /var/folders/0q/6gj5hsjn61s17q78d8lj21980000gn/T/blobStore-fa920b28-0308-42f8-bb10-2058413432d9
2023-04-04 09:38:30  [ main:6773 ] - [ INFO ]  Started BLOB server at 0.0.0.0:58030 - max concurrent requests: 50 - max backlog: 1000
2023-04-04 09:38:30  [ main:6987 ] - [ INFO ]  Created BLOB cache storage directory /var/folders/0q/6gj5hsjn61s17q78d8lj21980000gn/T/blobStore-2ff927a1-83e9-4bef-b611-ccc649a81ab7
2023-04-04 09:38:30  [ main:6989 ] - [ INFO ]  Created BLOB cache storage directory /var/folders/0q/6gj5hsjn61s17q78d8lj21980000gn/T/blobStore-5e6b729a-a89c-46c5-b2a1-2a5611006890
2023-04-04 09:38:30  [ main:6989 ] - [ INFO ]  Starting 1 TaskManager(s)
2023-04-04 09:38:30  [ main:6993 ] - [ INFO ]  Starting TaskManager with ResourceID: 208d17cb-f6a5-4219-8c5a-f99909666db4
2023-04-04 09:38:30  [ main:7002 ] - [ INFO ]  Temporary file directory '/var/folders/0q/6gj5hsjn61s17q78d8lj21980000gn/T': total 460 GB, usable 307 GB (66.74% usable)
2023-04-04 09:38:30  [ main:7005 ] - [ INFO ]  Created a new FileChannelManager for spilling of task related data to disk (joins, sorting, ...). Used directories:
	/var/folders/0q/6gj5hsjn61s17q78d8lj21980000gn/T/flink-io-5629135d-70a3-44b4-8b37-c6dc47902118
2023-04-04 09:38:30  [ main:7010 ] - [ INFO ]  Created a new FileChannelManager for storing result partitions of BLOCKING shuffles. Used directories:
	/var/folders/0q/6gj5hsjn61s17q78d8lj21980000gn/T/flink-netty-shuffle-6cc4fc0c-49ff-4684-b5d5-ca95ac7b0faa
2023-04-04 09:38:30  [ main:7025 ] - [ INFO ]  Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2023-04-04 09:38:30  [ main:7033 ] - [ INFO ]  Starting the network environment and its components.
2023-04-04 09:38:30  [ main:7034 ] - [ INFO ]  Starting the kvState service and its components.
2023-04-04 09:38:30  [ main:7041 ] - [ INFO ]  Config uses fallback configuration key 'akka.ask.timeout' instead of key 'taskmanager.slot.timeout'
2023-04-04 09:38:30  [ main:7051 ] - [ INFO ]  Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
2023-04-04 09:38:30  [ flink-akka.actor.default-dispatcher-5:7060 ] - [ INFO ]  Start job leader service.
2023-04-04 09:38:30  [ flink-akka.actor.default-dispatcher-5:7061 ] - [ INFO ]  User file cache uses directory /var/folders/0q/6gj5hsjn61s17q78d8lj21980000gn/T/flink-dist-cache-39416701-8a4b-4b00-8e6d-4eb3d57bdddb
2023-04-04 09:38:30  [ main:7080 ] - [ INFO ]  Upload directory /var/folders/0q/6gj5hsjn61s17q78d8lj21980000gn/T/flink-web-upload does not exist. 
2023-04-04 09:38:30  [ main:7081 ] - [ INFO ]  Created directory /var/folders/0q/6gj5hsjn61s17q78d8lj21980000gn/T/flink-web-upload for file uploads.
2023-04-04 09:38:31  [ main:7095 ] - [ INFO ]  Starting rest endpoint.
2023-04-04 09:38:31  [ main:7304 ] - [ WARN ]  Log file environment variable 'log.file' is not set.
2023-04-04 09:38:31  [ main:7304 ] - [ WARN ]  JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'web.log.path'.
2023-04-04 09:38:31  [ main:7411 ] - [ INFO ]  Rest endpoint listening at localhost:58035
2023-04-04 09:38:31  [ main:7412 ] - [ INFO ]  Proposing leadership to contender http://localhost:58035
2023-04-04 09:38:31  [ main:7413 ] - [ INFO ]  Web frontend listening at http://localhost:58035.
2023-04-04 09:38:31  [ mini-cluster-io-thread-1:7414 ] - [ INFO ]  http://localhost:58035 was granted leadership with leaderSessionID=9946cad4-9482-4ea1-b424-7a79eb8b71c8
2023-04-04 09:38:31  [ mini-cluster-io-thread-1:7414 ] - [ INFO ]  Received confirmation of leadership for leader http://localhost:58035 , session=9946cad4-9482-4ea1-b424-7a79eb8b71c8
2023-04-04 09:38:31  [ main:7422 ] - [ INFO ]  Proposing leadership to contender LeaderContender: DefaultDispatcherRunner
2023-04-04 09:38:31  [ main:7422 ] - [ INFO ]  Starting resource manager service.
2023-04-04 09:38:31  [ main:7423 ] - [ INFO ]  Proposing leadership to contender LeaderContender: ResourceManagerServiceImpl
2023-04-04 09:38:31  [ mini-cluster-io-thread-2:7423 ] - [ INFO ]  DefaultDispatcherRunner was granted leadership with leader id 46f56e9c-5f58-4091-bdae-6f5a85106a2b. Creating new DispatcherLeaderProcess.
2023-04-04 09:38:31  [ pool-6-thread-1:7423 ] - [ INFO ]  Resource manager service is granted leadership with session id e6fcb439-1635-4a80-894b-bd70e1da289f.
2023-04-04 09:38:31  [ main:7425 ] - [ INFO ]  Flink Mini Cluster started successfully
2023-04-04 09:38:31  [ mini-cluster-io-thread-2:7427 ] - [ INFO ]  Start SessionDispatcherLeaderProcess.
2023-04-04 09:38:31  [ mini-cluster-io-thread-1:7428 ] - [ INFO ]  Recover all persisted job graphs.
2023-04-04 09:38:31  [ mini-cluster-io-thread-1:7428 ] - [ INFO ]  Successfully recovered 0 persisted job graphs.
2023-04-04 09:38:31  [ mini-cluster-io-thread-1:7434 ] - [ INFO ]  Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/rpc/dispatcher_1 .
2023-04-04 09:38:31  [ pool-6-thread-1:7436 ] - [ INFO ]  Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/rpc/resourcemanager_2 .
2023-04-04 09:38:31  [ mini-cluster-io-thread-1:7448 ] - [ INFO ]  Received confirmation of leadership for leader akka://flink/user/rpc/dispatcher_1 , session=46f56e9c-5f58-4091-bdae-6f5a85106a2b
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-5:7448 ] - [ INFO ]  Starting the resource manager.
2023-04-04 09:38:31  [ mini-cluster-io-thread-2:7454 ] - [ INFO ]  Received confirmation of leadership for leader akka://flink/user/rpc/resourcemanager_2 , session=e6fcb439-1635-4a80-894b-bd70e1da289f
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-7:7455 ] - [ INFO ]  Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_2(894bbd70e1da289fe6fcb43916354a80).
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-8:7473 ] - [ INFO ]  Resolved ResourceManager address, beginning registration
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-7:7477 ] - [ INFO ]  Registering TaskManager with ResourceID 208d17cb-f6a5-4219-8c5a-f99909666db4 (akka://flink/user/rpc/taskmanager_0) at ResourceManager
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-7:7478 ] - [ INFO ]  Successful registration at resource manager akka://flink/user/rpc/resourcemanager_2 under registration id ca55f3f09c71bceb96f60d362be5be82.
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-5:7478 ] - [ INFO ]  Received JobGraph submission 'insert-into_default_catalog.default_database.employee_dimission' (cdc25694caf003976bb6d4d24a301751).
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-5:7479 ] - [ INFO ]  Submitting job 'insert-into_default_catalog.default_database.employee_dimission' (cdc25694caf003976bb6d4d24a301751).
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-5:7488 ] - [ INFO ]  Proposing leadership to contender LeaderContender: JobMasterServiceLeadershipRunner
2023-04-04 09:38:31  [ jobmanager-io-thread-1:7495 ] - [ INFO ]  Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_3 .
2023-04-04 09:38:31  [ jobmanager-io-thread-1:7501 ] - [ INFO ]  Initializing job 'insert-into_default_catalog.default_database.employee_dimission' (cdc25694caf003976bb6d4d24a301751).
2023-04-04 09:38:31  [ jobmanager-io-thread-1:7514 ] - [ INFO ]  Using restart back off time strategy NoRestartBackoffTimeStrategy for insert-into_default_catalog.default_database.employee_dimission (cdc25694caf003976bb6d4d24a301751).
2023-04-04 09:38:31  [ jobmanager-io-thread-1:7546 ] - [ INFO ]  Running initialization on master for job insert-into_default_catalog.default_database.employee_dimission (cdc25694caf003976bb6d4d24a301751).
2023-04-04 09:38:31  [ jobmanager-io-thread-1:7546 ] - [ INFO ]  Successfully ran initialization on master in 0 ms.
2023-04-04 09:38:31  [ jobmanager-io-thread-1:7622 ] - [ INFO ]  Built 1 pipelined regions in 1 ms
2023-04-04 09:38:31  [ jobmanager-io-thread-1:7639 ] - [ INFO ]  Using application-defined state backend: org.apache.flink.streaming.api.operators.sorted.state.BatchExecutionStateBackend@3dd5199d
2023-04-04 09:38:31  [ jobmanager-io-thread-1:7639 ] - [ INFO ]  State backend loader loads the state backend as BatchExecutionStateBackend
2023-04-04 09:38:31  [ jobmanager-io-thread-1:7640 ] - [ INFO ]  Using application defined checkpoint storage: org.apache.flink.streaming.api.operators.sorted.state.BatchExecutionCheckpointStorage@7a1ebf68
2023-04-04 09:38:31  [ jobmanager-io-thread-1:7649 ] - [ INFO ]  No checkpoint found during restore.
2023-04-04 09:38:31  [ jobmanager-io-thread-1:7652 ] - [ INFO ]  Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@3763ed37 for insert-into_default_catalog.default_database.employee_dimission (cdc25694caf003976bb6d4d24a301751).
2023-04-04 09:38:31  [ jobmanager-io-thread-1:7658 ] - [ INFO ]  Received confirmation of leadership for leader akka://flink/user/rpc/jobmanager_3 , session=fa2d6325-c9d5-454b-bfad-87d2dda1c783
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-7:7659 ] - [ INFO ]  Starting execution of job 'insert-into_default_catalog.default_database.employee_dimission' (cdc25694caf003976bb6d4d24a301751) under job master id bfad87d2dda1c783fa2d6325c9d5454b.
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-7:7660 ] - [ INFO ]  Starting split enumerator for source Source: HiveSource-dwd.employee_dimission.
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-7:7806 ] - [ INFO ]  Total input files to process : 1
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-7:7808 ] - [ INFO ]  Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-7:7808 ] - [ INFO ]  Job insert-into_default_catalog.default_database.employee_dimission (cdc25694caf003976bb6d4d24a301751) switched from state CREATED to RUNNING.
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-7:7810 ] - [ INFO ]  Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1) (72e98f849bbf73a804583dda147413fd) switched from CREATED to SCHEDULED.
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-7:7820 ] - [ INFO ]  Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_2(894bbd70e1da289fe6fcb43916354a80)
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-7:7821 ] - [ INFO ]  Resolved ResourceManager address, beginning registration
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-5:7823 ] - [ INFO ]  Registering job manager bfad87d2dda1c783fa2d6325c9d5454b@akka://flink/user/rpc/jobmanager_3 for job cdc25694caf003976bb6d4d24a301751.
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-8:7826 ] - [ INFO ]  Registered job manager bfad87d2dda1c783fa2d6325c9d5454b@akka://flink/user/rpc/jobmanager_3 for job cdc25694caf003976bb6d4d24a301751.
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-8:7827 ] - [ INFO ]  JobManager successfully registered at ResourceManager, leader id: 894bbd70e1da289fe6fcb43916354a80.
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-5:7828 ] - [ INFO ]  Received resource requirements from job cdc25694caf003976bb6d4d24a301751: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-8:7832 ] - [ INFO ]  Receive slot request 37b1aad54de40904f4c274807024cd3b for job cdc25694caf003976bb6d4d24a301751 from resource manager with leader id 894bbd70e1da289fe6fcb43916354a80.
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-8:7835 ] - [ INFO ]  Allocated slot for 37b1aad54de40904f4c274807024cd3b.
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-8:7836 ] - [ INFO ]  Add job cdc25694caf003976bb6d4d24a301751 for job leader monitoring.
2023-04-04 09:38:31  [ mini-cluster-io-thread-4:7837 ] - [ INFO ]  Try to register at job manager akka://flink/user/rpc/jobmanager_3 with leader id fa2d6325-c9d5-454b-bfad-87d2dda1c783.
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-9:7838 ] - [ INFO ]  Resolved JobManager address, beginning registration
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-5:7840 ] - [ INFO ]  Successful registration at job manager akka://flink/user/rpc/jobmanager_3 for job cdc25694caf003976bb6d4d24a301751.
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-5:7840 ] - [ INFO ]  Establish JobManager connection for job cdc25694caf003976bb6d4d24a301751.
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-5:7842 ] - [ INFO ]  Offer reserved slots to the leader of job cdc25694caf003976bb6d4d24a301751.
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-7:7845 ] - [ INFO ]  Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1) (72e98f849bbf73a804583dda147413fd) switched from SCHEDULED to DEPLOYING.
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-7:7846 ] - [ INFO ]  Deploying Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1) (attempt #0) with attempt id 72e98f849bbf73a804583dda147413fd to 208d17cb-f6a5-4219-8c5a-f99909666db4 @ localhost (dataPort=-1) with allocation id 37b1aad54de40904f4c274807024cd3b
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-5:7850 ] - [ INFO ]  Activate slot 37b1aad54de40904f4c274807024cd3b.
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-5:7858 ] - [ INFO ]  StateChangelogStorageLoader initialized with shortcut names {memory}.
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-5:7858 ] - [ INFO ]  Creating a changelog storage with name 'memory'.
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-5:7869 ] - [ INFO ]  Received task Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1)#0 (72e98f849bbf73a804583dda147413fd), deploy into slot with allocation id 37b1aad54de40904f4c274807024cd3b.
2023-04-04 09:38:31  [ Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1)#0:7870 ] - [ INFO ]  Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1)#0 (72e98f849bbf73a804583dda147413fd) switched from CREATED to DEPLOYING.
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-5:7871 ] - [ INFO ]  Activate slot 37b1aad54de40904f4c274807024cd3b.
2023-04-04 09:38:31  [ Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1)#0:7873 ] - [ INFO ]  Loading JAR files for task Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1)#0 (72e98f849bbf73a804583dda147413fd) [DEPLOYING].
2023-04-04 09:38:31  [ Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1)#0:7883 ] - [ INFO ]  Using application-defined state backend: org.apache.flink.streaming.api.operators.sorted.state.BatchExecutionStateBackend@31cefdc5
2023-04-04 09:38:31  [ Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1)#0:7883 ] - [ INFO ]  State backend loader loads the state backend as BatchExecutionStateBackend
2023-04-04 09:38:31  [ Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1)#0:7883 ] - [ INFO ]  Using application defined checkpoint storage: org.apache.flink.streaming.api.operators.sorted.state.BatchExecutionCheckpointStorage@96183fe
2023-04-04 09:38:31  [ Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1)#0:7886 ] - [ INFO ]  Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1)#0 (72e98f849bbf73a804583dda147413fd) switched from DEPLOYING to INITIALIZING.
2023-04-04 09:38:31  [ flink-akka.actor.default-dispatcher-5:7887 ] - [ INFO ]  Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1) (72e98f849bbf73a804583dda147413fd) switched from DEPLOYING to INITIALIZING.
2023-04-04 09:38:31  [ Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1)#0:7948 ] - [ WARN ]  The operator name Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) exceeded the 80 characters length limit and was truncated.
2023-04-04 09:38:32  [ SourceCoordinator-Source: HiveSource-dwd.employee_dimission:8920 ] - [ INFO ]  Source Source: HiveSource-dwd.employee_dimission registering reader for parallel task 0 @ 
2023-04-04 09:38:32  [ SourceCoordinator-Source: HiveSource-dwd.employee_dimission:8921 ] - [ INFO ]  Source Source: HiveSource-dwd.employee_dimission received split request from parallel task 0
2023-04-04 09:38:32  [ Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1)#0:8922 ] - [ INFO ]  Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1)#0 (72e98f849bbf73a804583dda147413fd) switched from INITIALIZING to RUNNING.
2023-04-04 09:38:32  [ SourceCoordinator-Source: HiveSource-dwd.employee_dimission:8922 ] - [ INFO ]  Subtask 0 (on host '') is requesting a file source split
2023-04-04 09:38:32  [ flink-akka.actor.default-dispatcher-5:8922 ] - [ INFO ]  Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1) (72e98f849bbf73a804583dda147413fd) switched from INITIALIZING to RUNNING.
2023-04-04 09:38:32  [ SourceCoordinator-Source: HiveSource-dwd.employee_dimission:8923 ] - [ INFO ]  Assigning split to non-localized request: Optional[HiveSourceSplit{Path=hdfs://Tdsop/user/hive/warehouse/dwd.db/employee_dimission/000000_0, Offset=0, Length=1368003, Position=null, HiveTablePartition=HiveTablePartition{PartitionSpec={}, Location=hdfs://Tdsop/user/hive/warehouse/dwd.db/employee_dimission, InputFormat=org.apache.hadoop.mapred.TextInputFormat}}]
2023-04-04 09:38:32  [ SourceCoordinator-Source: HiveSource-dwd.employee_dimission:8927 ] - [ INFO ]  Assigned split to subtask 0 : HiveSourceSplit{Path=hdfs://Tdsop/user/hive/warehouse/dwd.db/employee_dimission/000000_0, Offset=0, Length=1368003, Position=null, HiveTablePartition=HiveTablePartition{PartitionSpec={}, Location=hdfs://Tdsop/user/hive/warehouse/dwd.db/employee_dimission, InputFormat=org.apache.hadoop.mapred.TextInputFormat}}
2023-04-04 09:38:32  [ Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1)#0:8929 ] - [ INFO ]  Adding split(s) to reader: [HiveSourceSplit{Path=hdfs://Tdsop/user/hive/warehouse/dwd.db/employee_dimission/000000_0, Offset=0, Length=1368003, Position=null, HiveTablePartition=HiveTablePartition{PartitionSpec={}, Location=hdfs://Tdsop/user/hive/warehouse/dwd.db/employee_dimission, InputFormat=org.apache.hadoop.mapred.TextInputFormat}}]
2023-04-04 09:38:32  [ Source Data Fetcher for Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1)#0:8934 ] - [ INFO ]  Starting split fetcher 0
2023-04-04 09:38:33  [ Source Data Fetcher for Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1)#0:9755 ] - [ INFO ]  Finished reading from splits [hdfs://Tdsop/user/hive/warehouse/dwd.db/employee_dimission/000000_0:0+1368003]
2023-04-04 09:38:33  [ Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1)#0:9757 ] - [ INFO ]  Finished reading split(s) [hdfs://Tdsop/user/hive/warehouse/dwd.db/employee_dimission/000000_0:0+1368003]
2023-04-04 09:38:33  [ Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1)#0:9757 ] - [ INFO ]  Closing splitFetcher 0 because it is idle.
2023-04-04 09:38:33  [ Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1)#0:9758 ] - [ INFO ]  Shutting down split fetcher 0
2023-04-04 09:38:33  [ SourceCoordinator-Source: HiveSource-dwd.employee_dimission:9758 ] - [ INFO ]  Source Source: HiveSource-dwd.employee_dimission received split request from parallel task 0
2023-04-04 09:38:33  [ Source Data Fetcher for Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1)#0:9758 ] - [ INFO ]  Split fetcher 0 exited.
2023-04-04 09:38:33  [ SourceCoordinator-Source: HiveSource-dwd.employee_dimission:9758 ] - [ INFO ]  Subtask 0 (on host '') is requesting a file source split
2023-04-04 09:38:33  [ SourceCoordinator-Source: HiveSource-dwd.employee_dimission:9759 ] - [ INFO ]  No more splits available for subtask 0
2023-04-04 09:38:33  [ Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1)#0:9759 ] - [ INFO ]  Reader received NoMoreSplits event.
2023-04-04 09:40:24  [ Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1)#0:120484 ] - [ INFO ]  Closing Source Reader.
2023-04-04 09:40:24  [ Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1)#0:120490 ] - [ INFO ]  Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1)#0 (72e98f849bbf73a804583dda147413fd) switched from RUNNING to FINISHED.
2023-04-04 09:40:24  [ Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1)#0:120491 ] - [ INFO ]  Freeing task resources for Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1)#0 (72e98f849bbf73a804583dda147413fd).
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-26:120494 ] - [ INFO ]  Un-registering task and sending final execution state FINISHED to JobManager for task Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1)#0 72e98f849bbf73a804583dda147413fd.
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-31:120498 ] - [ INFO ]  Source: HiveSource-dwd.employee_dimission -> Sink: Sink(table=[default_catalog.default_database.employee_dimission], fields=[pk_date, staff_record_id, employee_id, dimission_date, dimission_type_chinese, dimission_nature, reason1, reason2, reason3, reason1_chinese, reason1_chinese_desc, record_time, record_end_time, record_type, dimission_reason_desc, new_unit_id, old_unit_id, new_employee_status, old_employee_status, old_employee_type, new_employee_type, old_unit_path_name, new_unit_path_name, old_emp_level, new_emp_level, old_job_group, old_job_family_name, old_job_type_chinese, old_department, old_department_fl, old_department_level, old_level1, old_level2, old_level3, old_level4, old_level5]) (1/1) (72e98f849bbf73a804583dda147413fd) switched from RUNNING to FINISHED.
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-31:120506 ] - [ INFO ]  Job insert-into_default_catalog.default_database.employee_dimission (cdc25694caf003976bb6d4d24a301751) switched from state RUNNING to FINISHED.
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-26:120506 ] - [ INFO ]  Clearing resource requirements of job cdc25694caf003976bb6d4d24a301751
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-31:120507 ] - [ INFO ]  Stopping checkpoint coordinator for job cdc25694caf003976bb6d4d24a301751.
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-26:120520 ] - [ INFO ]  Shutting down Flink Mini Cluster
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-30:120520 ] - [ INFO ]  Job cdc25694caf003976bb6d4d24a301751 reached terminal state FINISHED.
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-31:120521 ] - [ INFO ]  Stopping TaskExecutor akka://flink/user/rpc/taskmanager_0.
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-31:120521 ] - [ INFO ]  Close ResourceManager connection c9caa5c0e352a18fd05bb473f76705d0.
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-26:120521 ] - [ INFO ]  Shutting down rest endpoint.
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-32:120522 ] - [ INFO ]  Closing TaskExecutor connection 208d17cb-f6a5-4219-8c5a-f99909666db4 because: The TaskExecutor is shutting down.
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-31:120522 ] - [ INFO ]  Close JobManager connection for job cdc25694caf003976bb6d4d24a301751.
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-32:120523 ] - [ INFO ]  Stopping the JobMaster for job 'insert-into_default_catalog.default_database.employee_dimission' (cdc25694caf003976bb6d4d24a301751).
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-31:120524 ] - [ INFO ]  Shutting down TaskExecutorStateChangelogStoragesManager.
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-31:120525 ] - [ INFO ]  Free slot TaskSlot(index:0, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=1024.000gb (1099511627776 bytes), taskOffHeapMemory=1024.000gb (1099511627776 bytes), managedMemory=128.000mb (134217728 bytes), networkMemory=64.000mb (67108864 bytes)}, allocationId: 37b1aad54de40904f4c274807024cd3b, jobId: cdc25694caf003976bb6d4d24a301751).
2023-04-04 09:40:24  [ Thread-14:120527 ] - [ INFO ]  Closing SourceCoordinator for source Source: HiveSource-dwd.employee_dimission.
2023-04-04 09:40:24  [ Thread-14:120528 ] - [ INFO ]  Source coordinator for source Source: HiveSource-dwd.employee_dimission closed.
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-32:120531 ] - [ INFO ]  Shutting down
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-31:120532 ] - [ INFO ]  Stop job leader service.
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-31:120533 ] - [ INFO ]  Shutting down TaskExecutorLocalStateStoresManager.
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-32:120533 ] - [ INFO ]  Releasing slot [37b1aad54de40904f4c274807024cd3b].
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-32:120535 ] - [ INFO ]  Close ResourceManager connection c9caa5c0e352a18fd05bb473f76705d0: Stopping JobMaster for job 'insert-into_default_catalog.default_database.employee_dimission' (cdc25694caf003976bb6d4d24a301751).
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-30:120536 ] - [ INFO ]  Disconnect job manager bfad87d2dda1c783fa2d6325c9d5454b@akka://flink/user/rpc/jobmanager_3 for job cdc25694caf003976bb6d4d24a301751 from the resource manager.
2023-04-04 09:40:24  [ ForkJoinPool.commonPool-worker-0:120542 ] - [ INFO ]  Removing cache directory /var/folders/0q/6gj5hsjn61s17q78d8lj21980000gn/T/flink-web-ui
2023-04-04 09:40:24  [ ForkJoinPool.commonPool-worker-0:120544 ] - [ INFO ]  Shut down complete.
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-31:120546 ] - [ INFO ]  FileChannelManager removed spill file directory /var/folders/0q/6gj5hsjn61s17q78d8lj21980000gn/T/flink-io-5629135d-70a3-44b4-8b37-c6dc47902118
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-31:120546 ] - [ INFO ]  Shutting down the network environment and its components.
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-30:120547 ] - [ INFO ]  Shut down cluster because application is in CANCELED, diagnostics DispatcherResourceManagerComponent has been closed..
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-30:120548 ] - [ INFO ]  Closing components.
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-30:120548 ] - [ INFO ]  Stopping SessionDispatcherLeaderProcess.
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-32:120549 ] - [ INFO ]  Stopping dispatcher akka://flink/user/rpc/dispatcher_1.
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-30:120549 ] - [ INFO ]  Stopping resource manager service.
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-32:120549 ] - [ INFO ]  Stopping all currently running jobs of dispatcher akka://flink/user/rpc/dispatcher_1.
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-30:120550 ] - [ INFO ]  Closing the slot manager.
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-30:120550 ] - [ INFO ]  Suspending the slot manager.
2023-04-04 09:40:24  [ mini-cluster-io-thread-2:120552 ] - [ INFO ]  Stopped dispatcher akka://flink/user/rpc/dispatcher_1.
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-31:120553 ] - [ INFO ]  FileChannelManager removed spill file directory /var/folders/0q/6gj5hsjn61s17q78d8lj21980000gn/T/flink-netty-shuffle-6cc4fc0c-49ff-4684-b5d5-ca95ac7b0faa
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-31:120553 ] - [ INFO ]  Shutting down the kvState service and its components.
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-31:120554 ] - [ INFO ]  Stop job leader service.
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-31:120556 ] - [ INFO ]  removed file cache directory /var/folders/0q/6gj5hsjn61s17q78d8lj21980000gn/T/flink-dist-cache-39416701-8a4b-4b00-8e6d-4eb3d57bdddb
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-31:120557 ] - [ INFO ]  Stopped TaskExecutor akka://flink/user/rpc/taskmanager_0.
2023-04-04 09:40:24  [ AkkaRpcService-Supervisor-Termination-Future-Executor-thread-1:120558 ] - [ INFO ]  Stopping Akka RPC service.
2023-04-04 09:40:24  [ flink-metrics-7:120607 ] - [ INFO ]  Stopping Akka RPC service.
2023-04-04 09:40:24  [ flink-metrics-7:120607 ] - [ INFO ]  Stopped Akka RPC service.
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-30:120616 ] - [ INFO ]  Shutting down BLOB cache
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-30:120618 ] - [ INFO ]  Shutting down BLOB cache
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-30:120624 ] - [ INFO ]  Stopped BLOB server at 0.0.0.0:58030
2023-04-04 09:40:24  [ flink-akka.actor.default-dispatcher-30:120626 ] - [ INFO ]  Stopped Akka RPC service.
